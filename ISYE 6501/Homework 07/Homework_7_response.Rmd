---
title: "Homework_7"
author: "Claire Kraft"
date: "2024-10-08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Question 10.1
**Using the same crime data set uscrime.txt as in Questions 8.2 and 9.1, find the best model you can using (a) a regression tree model, and (b) a random forest model.**
**In R, you can use the tree package or the rpart package, and the randomForest package. For each model, describe one or two qualitative takeaways you get from analyzing the results (i.e., don’t just stop when you have a good model, but interpret it too).**

In the regression tree it seems there are 4 "generations". The children are Po1, Pop, LF, NW. In the model validation section the R^2 result is 72.445%. R^2 is the metric used to measure the fitness of the model. The closer that the R^2 gets to 100 the better fit the model is. 72% is closer to 100% os the model fits nearly perfectly. 
```{r reg tree}
# Set up
rm(list = ls())

# Helper 
library(tree)
#install.packages("caret")
library(caret)

# Read in data
uscrime <- read.table("~/GitHub/omsa/ISYE 6501/Homework 07/uscrime.txt", stringsAsFactors = FALSE, header = TRUE)
head(uscrime)

# Fit a reg tree
crime_tree <- tree(Crime~., data = uscrime)
summary(crime_tree)

# Plot tree
plot(crime_tree)
text(crime_tree ,pretty =0)
crime_tree
```

```{r eval reg}
# Read in data
uscrime <- read.table("~/GitHub/omsa/ISYE 6501/Homework 07/uscrime.txt", stringsAsFactors = FALSE, header = TRUE)
head(uscrime)

# Fit a reg tree
crime_tree <- tree(Crime~., data = uscrime)

# nMake predictions on the training data
predicted_values <- predict(crime_tree, newdata = uscrime)
summary(predicted_values)

# Calculate Mean Squared Error (MSE)
mse <- mean((uscrime$Crime - predicted_values)^2)
mse

# Calculate R-squared
sst <- sum((uscrime$Crime - mean(uscrime$Crime))^2)
sst

sse <- sum((uscrime$Crime - predicted_values)^2)
sse

r2 <- 1 - (sse / sst) #1- 6880928/40334.5
r2
```

```{r random forrest}
# Set up
rm(list = ls())

# Set seed for reproducibility.
set.seed(478)

# Train a regression model using 5-fold cross-validation.
cvrm <- train(Crime ~ ., data = uscrime,
              trControl = trainControl(method = 'cv', number = 5, savePredictions = TRUE),
              tuneGrid = expand.grid(mtry = 1:15))
cvrm
# Print the trained cross-validated regression model.

# Calculate the sum of squared errors (SSE) for the regression model.
SSErm <- sum((cvrm$pred[,2] - cvrm$pred[,1])^2)
SSErm
# Print the SSE.

# Calculate the total sum of squares (SST) for the regression model.
SSTrm <- sum((cvrm$pred[,2] - mean(cvrm$pred[,2]))^2)
SSTrm
# Print the SST.

# Calculate the R-squared value for the regression model.
r2 <- 1 - (SSErm / SSTrm)
r2
# Print the R-squared value.

```

## Question 10.2
**Describe a situation or problem from your job, everyday life, current events, etc., for which a logistic regression model would be appropriate. List some (up to 5) predictors that you might use.**

Logistic regression is like linear regression except it is more useful for discrete variables. Discrete variables are like integers where the values are finite. Linear regression is good for continuous variables which are like are like floats. Some possible predictors could be 
- Work at home (1) or go in the office (0)
- Go climbing (1) or stay at home (0)
- Travel abroad (1) or stay-cation (0)
- Cook at home (1) or take out (0)


### Question 10.3.1
**Using the GermanCredit data set germancredit.txt from http://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german / (description at http://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29 ), use logistic regression to find a good predictive model for whether credit applicants are good credit risks or not. Show your model (factors used and their coefficients), the software output, and the quality of fit. You can use the glm function in R. To get a logistic regression (logit) model on data where the response is either zero or one, use family=binomial(link=”logit”) in your glm function call.**

answer
```{r log reg}
#code
```

### Question 10.3.2
**Because the model gives a result between 0 and 1, it requires setting a threshold probability to separate between “good” and “bad” answers. In this data set, they estimate that incorrectly identifying a bad customer as good, is 5 times worse than incorrectly classifying a good customer as bad. Determine a good threshold probability based on your model.**


answer
```{r code}
#code
```

References:

[1] APA citation

[2] APA citation

[3] APA citation

[4] APA citation

[5] APA citation

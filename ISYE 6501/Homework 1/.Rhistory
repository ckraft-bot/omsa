a0 <- -model@b
print("a0 intercept: ")
print(a0)
#------------------------- predicting the data
# see what the model predicts
pred <- predict(model,credit_matrix[,1:10])
print("Prediction: ")
print(pred)
# see what fraction of the model’s predictions match the actual classification
accuracy <- sum(pred == credit_matrix[,11]) / nrow(credit_matrix)
# accuracy of the model by comparing predictions to actual class labels
print("Accuracy of model: ")
print(accuracy)
#------------------------- getting a sense of the data
# read in credit_card_data data (source: https://teacherscollege.screenstepslive.com/a/1126998-import-data-into-r-txt-files-in-r-studio)
credit <- read.table("C://Users//Clair//OneDrive//Documents//Fall 2024//IYSE 6501//hw1//data 2.2//credit_card_data.txt", sep="\t", header=FALSE)
# View a summary of the dataset including basic statistics for each column
summary(credit)
# get dimension of df, row x column
dim(credit)
# look for null values
print("Count of total missing values: ")
sum(is.na(credit))
#------------------------- manipulating the data
# convert .txt > df > matrix (source: https://stackoverflow.com/questions/46518838/how-to-convert-table-to-matrix-in-r)
credit_matrix <- data.matrix(credit)
head(credit_matrix)
#------------------------- helper
# install the kernlab package
#install.packages("kernlab")
# load kernlab library
library(kernlab)
#------------------------- training the data
# call ksvm(), Vanilladot is a simple linear kernel
# train the model using the first 10 columns as features, 11th column is the target
# parameter is c=x
model <- ksvm(credit_matrix[,1:10],as.factor(credit_matrix[,11]),type="C-svc",kernel="vanilladot",C=1,scaled=TRUE)
# calculate a1…am
a <- colSums(model@xmatrix[[1]] * model@coef[[1]])
print("Equation: ")
print(a)
# calculate a0
a0 <- -model@b
print("a0 intercept: ")
print(a0)
#------------------------- predicting the data
# see what the model predicts
pred <- predict(model,credit_matrix[,1:10])
print("Prediction: ")
print(pred)
# see what fraction of the model’s predictions match the actual classification
accuracy <- sum(pred == credit_matrix[,11]) / nrow(credit_matrix)
# accuracy of the model by comparing predictions to actual class labels
print("Accuracy of model: ")
print(accuracy)
#------------------------- getting a sense of the data
# read in credit_card_data data (source: https://teacherscollege.screenstepslive.com/a/1126998-import-data-into-r-txt-files-in-r-studio)
credit <- read.table("C://Users//Clair//OneDrive//Documents//Fall 2024//IYSE 6501//hw1//data 2.2//credit_card_data.txt", sep="\t", header=FALSE)
# View a summary of the dataset including basic statistics for each column
summary(credit)
# get dimension of df, row x column
print("Size of df: ")
dim(credit)
# look for null values
print("Count of total missing values: ")
sum(is.na(credit))
#------------------------- manipulating the data
# convert .txt > df > matrix (source: https://stackoverflow.com/questions/46518838/how-to-convert-table-to-matrix-in-r)
credit_matrix <- data.matrix(credit)
head(credit_matrix)
#------------------------- helper
# install the kernlab package
#install.packages("kernlab")
# load kernlab library
library(kernlab)
#------------------------- loop through 10 models with varying margins
# Define a vector to store accuracy for each model
accuracies <- c()
# Loop through values of C from 100 to 1000 in steps of 100
for (C_value in seq(100, 1000, by=100)) {
# Train an SVM model using the polydot kernel with varying C
model <- ksvm(credit_matrix[,1:10], as.factor(credit_matrix[,11]),
type="C-svc", kernel="polydot",
kpar=list(degree=3), C=C_value, scaled=TRUE)
# Predict the data using the trained model
pred <- predict(model, credit_matrix[,1:10])
# Calculate accuracy of the model by comparing predictions to actual class labels
accuracy <- sum(pred == credit_matrix[,11]) / nrow(credit_matrix)
# Print the C value and corresponding accuracy
print(paste("C =", C_value, "-> Accuracy:", accuracy))
# Store the accuracy for each model
accuracies <- c(accuracies, accuracy)
}
#------------------------- output final accuracies for each model
print("Accuracies for each model with varying margins:")
print(accuracies)
#------------------------- getting a sense of the data
# read in credit_card_data data (source: https://teacherscollege.screenstepslive.com/a/1126998-import-data-into-r-txt-files-in-r-studio)
credit <- read.table("C://Users//Clair//OneDrive//Documents//Fall 2024//IYSE 6501//hw1//data 2.2//credit_card_data.txt", sep="\t", header=FALSE)
# View a summary of the dataset including basic statistics for each column
# summary(credit) didn't change my dataset so don't need to reprint summary
# look for null values
#print("Count of total missing values: ")
#sum(is.na(credit)) didn't change my dataset so the missing values count have not changed
#------------------------- manipulating the data
# convert .txt > df > matrix (source: https://stackoverflow.com/questions/46518838/how-to-convert-table-to-matrix-in-r)
credit_matrix <- data.matrix(credit)
#head(credit_matrix) didn't change my dataset so don't need to reprint summary
#------------------------- helper
# install the kernlab package
#install.packages("kernlab")
# load kernlab library
library(kernlab)
#------------------------- loop through 10 models with varying margins
# Define a vector to store accuracy for each model
accuracies <- c()
# Loop through values of C from 100 to 1000 in steps of 100
for (C_value in seq(100, 1000, by=100)) {
# Train an SVM model using the RBF kernel with varying C
model <- ksvm(credit_matrix[,1:10], as.factor(credit_matrix[,11]),
type="C-svc", kernel="rbfdot",
C=C_value, scaled=TRUE)
# Predict the data using the trained model
pred <- predict(model, credit_matrix[,1:10])
# Calculate accuracy of the model by comparing predictions to actual class labels
accuracy <- sum(pred == credit_matrix[,11]) / nrow(credit_matrix)
# Print the C value and corresponding accuracy
print(paste("C =", C_value, "-> Accuracy:", accuracy))
# Store the accuracy for each model
accuracies <- c(accuracies, accuracy)
}
#------------------------- output final accuracies for each model
print("Accuracies for each model with varying margins:")
print(accuracies)
knitr::opts_chunk$set(echo = TRUE)
#------------------------- getting a sense of the data
# read in credit_card_data data (source: https://teacherscollege.screenstepslive.com/a/1126998-import-data-into-r-txt-files-in-r-studio)
credit <- read.table("C://Users//Clair//OneDrive//Documents//Fall 2024//IYSE 6501//hw1//data 2.2//credit_card_data.txt", sep="\t", header=FALSE)
# View a summary of the dataset including basic statistics for each column
# summary(credit) didn't change my dataset so don't need to reprint summary
# look for null values
#print("Count of total missing values: ")
#sum(is.na(credit)) didn't change my dataset so the missing values count have not changed
#------------------------- manipulating the data
# convert .txt > df > matrix (source: https://stackoverflow.com/questions/46518838/how-to-convert-table-to-matrix-in-r)
credit_matrix <- data.matrix(credit)
#head(credit_matrix) didn't change my dataset so don't need to reprint summary
#------------------------- helper
# install the kernlab package
#install.packages("kernlab")
# load kernlab library
library(kernlab)
#------------------------- loop through 10 models with varying margins
# Define a vector to store accuracy for each model
accuracies <- c()
# Loop through values of C from 100 to 1000 in steps of 100
for (C_value in seq(100, 1000, by=100)) {
# Train an SVM model using the polydot kernel with varying C
model <- ksvm(credit_matrix[,1:10], as.factor(credit_matrix[,11]),
type="C-svc", kernel="polydot",
kpar=list(degree=3), C=C_value, scaled=TRUE)
# Predict the data using the trained model
pred <- predict(model, credit_matrix[,1:10])
# Calculate accuracy of the model by comparing predictions to actual class labels
accuracy <- sum(pred == credit_matrix[,11]) / nrow(credit_matrix)
# Print the C value and corresponding accuracy
print(paste("C =", C_value, "-> Accuracy:", accuracy))
# Store the accuracy for each model
accuracies <- c(accuracies, accuracy)
}
#------------------------- output final accuracies for each model
print("Accuracies for each polynomial model with varying margins:")
print(accuracies)
#------------------------- getting a sense of the data
# read in credit_card_data data (source: https://teacherscollege.screenstepslive.com/a/1126998-import-data-into-r-txt-files-in-r-studio)
credit <- read.table("C://Users//Clair//OneDrive//Documents//Fall 2024//IYSE 6501//hw1//data 2.2//credit_card_data.txt", sep="\t", header=FALSE)
# View a summary of the dataset including basic statistics for each column
# summary(credit) didn't change my dataset so don't need to reprint summary
# look for null values
#print("Count of total missing values: ")
#sum(is.na(credit)) didn't change my dataset so the missing values count have not changed
#------------------------- manipulating the data
# convert .txt > df > matrix (source: https://stackoverflow.com/questions/46518838/how-to-convert-table-to-matrix-in-r)
credit_matrix <- data.matrix(credit)
#head(credit_matrix) didn't change my dataset so don't need to reprint summary
#------------------------- helper
# install the kernlab package
#install.packages("kernlab")
# load kernlab library
library(kernlab)
#------------------------- loop through 10 models with varying margins
# Define a vector to store accuracy for each model
accuracies <- c()
# Loop through values of C from 100 to 1000 in steps of 100
for (C_value in seq(100, 1000, by=100)) {
# Train an SVM model using the RBF kernel with varying C
model <- ksvm(credit_matrix[,1:10], as.factor(credit_matrix[,11]),
type="C-svc", kernel="rbfdot",
C=C_value, scaled=TRUE)
# Predict the data using the trained model
pred <- predict(model, credit_matrix[,1:10])
# Calculate accuracy of the model by comparing predictions to actual class labels
accuracy <- sum(pred == credit_matrix[,11]) / nrow(credit_matrix)
# Print the C value and corresponding accuracy
print(paste("C =", C_value, "-> Accuracy:", accuracy))
# Store the accuracy for each model
accuracies <- c(accuracies, accuracy)
}
#------------------------- output final accuracies for each model
print("Accuracies for each radial model with varying margins:")
print(accuracies)
#------------------------- getting a sense of the data
# read in credit_card_data data (source: https://teacherscollege.screenstepslive.com/a/1126998-import-data-into-r-txt-files-in-r-studio)
credit <- read.table("C://Users//Clair//OneDrive//Documents//Fall 2024//IYSE 6501//hw1//data 2.2//credit_card_data.txt", sep="\t", header=FALSE)
#------------------------- manipulating the data
# convert .txt > df > matrix (source: https://stackoverflow.com/questions/46518838/how-to-convert-table-to-matrix-in-r)
credit_matrix <- data.matrix(credit)
# load the class library for KNN
library(class)
#------------------------- split data into train and test sets
# Let's assume 70% training and 30% testing
set.seed(123)  # Set a seed for reproducibility
sample_indices <- sample(1:nrow(credit_matrix), size = 0.7 * nrow(credit_matrix))
train_data <- credit_matrix[sample_indices, 1:10]
train_labels <- as.factor(credit_matrix[sample_indices, 11])
test_data <- credit_matrix[-sample_indices, 1:10]
test_labels <- as.factor(credit_matrix[-sample_indices, 11])
#------------------------- loop through different values of K
# Define a vector to store accuracy for each K
accuracies <- c()
# Loop through values of K from 1 to 10
for (K_value in 1:10) {
# Use the knn function to make predictions
pred <- knn(train = train_data, test = test_data, cl = train_labels, k = K_value)
# Calculate accuracy by comparing predictions to actual class labels
accuracy <- sum(pred == test_labels) / length(test_labels)
# Print the K value and corresponding accuracy
print(paste("K =", K_value, "-> Accuracy:", accuracy))
# Store the accuracy for each model
accuracies <- c(accuracies, accuracy)
}
#------------------------- output final accuracies for each model
print("Accuracies for each KNN model with varying K:")
print(accuracies)
knitr::opts_chunk$set(echo = TRUE)
#------------------------- getting a sense of the data
# read in credit_card_data data (source: https://teacherscollege.screenstepslive.com/a/1126998-import-data-into-r-txt-files-in-r-studio)
credit <- read.table("C://Users//Clair//OneDrive//Documents//Fall 2024//IYSE 6501//hw1//data 2.2//credit_card_data.txt", sep="\t", header=FALSE)
# View a summary of the dataset including basic statistics for each column
summary(credit)
# get dimension of df, row x column
print("Size of df: ")
dim(credit)
# look for null values
print("Count of total missing values: ")
sum(is.na(credit))
#------------------------- manipulating the data
# convert .txt > df > matrix (source: https://stackoverflow.com/questions/46518838/how-to-convert-table-to-matrix-in-r)
credit_matrix <- data.matrix(credit)
head(credit_matrix)
#------------------------- helper
# install the kernlab package
#install.packages("kernlab")
# load kernlab library
library(kernlab)
#------------------------- training the data
# call ksvm(), Vanilladot is a simple linear kernel
# train the model using the first 10 columns as features, 11th column is the target
# parameter is c=x
model <- ksvm(credit_matrix[,1:10],as.factor(credit_matrix[,11]),type="C-svc",kernel="vanilladot",C=1,scaled=TRUE)
# calculate a1…am
a <- colSums(model@xmatrix[[1]] * model@coef[[1]])
print("Equation: ")
print(a)
# calculate a0
a0 <- -model@b
print("a0 intercept: ")
print(a0)
#------------------------- predicting the data
# see what the model predicts
pred <- predict(model,credit_matrix[,1:10])
print("Prediction: ")
print(pred)
# see what fraction of the model’s predictions match the actual classification
accuracy <- sum(pred == credit_matrix[,11]) / nrow(credit_matrix)
# accuracy of the model by comparing predictions to actual class labels
print("Accuracy of linear model: ")
print(accuracy)
#------------------------- getting a sense of the data
# read in credit_card_data data (source: https://teacherscollege.screenstepslive.com/a/1126998-import-data-into-r-txt-files-in-r-studio)
credit <- read.table("C://Users//Clair//OneDrive//Documents//Fall 2024//IYSE 6501//hw1//data 2.2//credit_card_data.txt", sep="\t", header=FALSE)
#------------------------- manipulating the data
# convert .txt > df > matrix (source: https://stackoverflow.com/questions/46518838/how-to-convert-table-to-matrix-in-r)
credit_matrix <- data.matrix(credit)
# load the class library for KNN
library(class)
#------------------------- split data into train and test sets
# Let's assume 70% training and 30% testing
set.seed(123)  # Set a seed for reproducibility
sample_indices <- sample(1:nrow(credit_matrix), size = 0.7 * nrow(credit_matrix))
train_data <- credit_matrix[sample_indices, 1:10]
train_labels <- as.factor(credit_matrix[sample_indices, 11])
test_data <- credit_matrix[-sample_indices, 1:10]
test_labels <- as.factor(credit_matrix[-sample_indices, 11])
#------------------------- loop through different values of K
# Define a vector to store accuracy for each K
accuracies <- c()
# Loop through values of K from 1 to 10
for (K_value in 1:10) {
# Use the knn function to make predictions
pred <- knn(train = train_data, test = test_data, cl = train_labels, k = K_value)
# Calculate accuracy by comparing predictions to actual class labels
accuracy <- sum(pred == test_labels) / length(test_labels)
# Print the K value and corresponding accuracy
print(paste("K =", K_value, "-> Accuracy:", accuracy))
# Store the accuracy for each model
accuracies <- c(accuracies, accuracy)
}
#------------------------- output final accuracies for each model
print("Accuracies for each KNN model with varying K:")
print(accuracies)
#------------------------- getting a sense of the data
# read in credit_card_data data (source: https://teacherscollege.screenstepslive.com/a/1126998-import-data-into-r-txt-files-in-r-studio)
credit <- read.table("C://Users//Clair//OneDrive//Documents//Fall 2024//IYSE 6501//hw1//data 2.2//credit_card_data.txt", sep="\t", header=FALSE)
# View a summary of the dataset including basic statistics for each column
summary(credit)
# get dimension of df, row x column
print("Size of df: ")
dim(credit)
# look for null values
print("Count of total missing values: ")
sum(is.na(credit))
#------------------------- manipulating the data
# convert .txt > df > matrix (source: https://stackoverflow.com/questions/46518838/how-to-convert-table-to-matrix-in-r)
credit_matrix <- data.matrix(credit)
head(credit_matrix)
#------------------------- helper
# install the kernlab package
#install.packages("kernlab")
# load kernlab library
library(kernlab)
#------------------------- training the data
# call ksvm(), Vanilladot is a simple linear kernel
# train the model using the first 10 columns as features, 11th column is the target
# parameter is c=x
model <- ksvm(credit_matrix[,1:10],as.factor(credit_matrix[,11]),type="C-svc",kernel="vanilladot",C=1,scaled=TRUE)
# calculate a1…am
a <- colSums(model@xmatrix[[1]] * model@coef[[1]])
print("Equation: ")
print(a)
# calculate a0
a0 <- -model@b
print("a0 intercept: ")
print(a0)
#------------------------- predicting the data
# see what the model predicts
pred <- predict(model,credit_matrix[,1:10])
print("Prediction: ")
print(pred)
# see what fraction of the model’s predictions match the actual classification
accuracy <- sum(pred == credit_matrix[,11]) / nrow(credit_matrix)
# accuracy of the model by comparing predictions to actual class labels
print("Accuracy of linear model: ")
print(accuracy)
#------------------------- getting a sense of the data
# read in credit_card_data data (source: https://teacherscollege.screenstepslive.com/a/1126998-import-data-into-r-txt-files-in-r-studio)
credit <- read.table("C://Users//Clair//OneDrive//Documents//Fall 2024//IYSE 6501//hw1//data 2.2//credit_card_data.txt", sep="\t", header=FALSE)
#------------------------- manipulating the data
# convert .txt > df > matrix (source: https://stackoverflow.com/questions/46518838/how-to-convert-table-to-matrix-in-r)
credit_matrix <- data.matrix(credit)
#------------------------- helper
library(class)
library(caTools)
#------------------------- split data into train and test sets
# Splitting the data into train and test sets with a 70-30 ratio
set.seed(123)  # For reproducibility
split <- sample.split(credit_matrix[, 11], SplitRatio = 0.7)
# Subset the credit_matrix into training and testing data
train_data <- subset(credit_matrix, split == TRUE)
test_data <- subset(credit_matrix, split == FALSE)
# Separating the features and labels for train and test data
train_features <- train_data[, 1:10]
train_labels <- as.factor(train_data[, 11])
test_features <- test_data[, 1:10]
test_labels <- as.factor(test_data[, 11])
# Feature Scaling
train_scale <- scale(train_features)
test_scale <- scale(test_features)
#------------------------- loop through different values of K
# Define a vector to store accuracy for each K
accuracies <- c()
# Loop through values of K from 1 to 10
for (K_value in 1:10) {
# Fitting knn model to training dataset
pred <- knn(train = train_scale,
test = test_scale,
cl = train_labels,
k = K_value)
# Calculate accuracy by comparing predictions to actual class labels
accuracy <- sum(pred == test_labels) / length(test_labels)
# Print the K value and corresponding accuracy
print(paste("K =", K_value, "-> Accuracy:", accuracy))
# Store the accuracy for each model
accuracies <- c(accuracies, accuracy)
}
#------------------------- output final accuracies for each model
print("Accuracies for each KNN model with varying K:")
print(accuracies)
#------------------------- getting a sense of the data
# read in credit_card_data data (source: https://teacherscollege.screenstepslive.com/a/1126998-import-data-into-r-txt-files-in-r-studio)
credit <- read.table("C://Users//Clair//OneDrive//Documents//Fall 2024//IYSE 6501//hw1//data 2.2//credit_card_data.txt", sep="\t", header=FALSE)
#------------------------- manipulating the data
# convert .txt > df > matrix (source: https://stackoverflow.com/questions/46518838/how-to-convert-table-to-matrix-in-r)
credit_matrix <- data.matrix(credit)
#------------------------- helper
library(class)
library(caTools)
#------------------------- split data into train and test sets
# Splitting the data into train and test sets with a 70-30 ratio
set.seed(123)  # For reproducibility
split <- sample.split(credit_matrix[, 11], SplitRatio = 0.7)
# Subset the credit_matrix into training and testing data
train_data <- subset(credit_matrix, split == TRUE)
test_data <- subset(credit_matrix, split == FALSE)
# Separating the features and labels for train and test data
train_features <- train_data[, 1:10]
train_labels <- as.factor(train_data[, 11])
test_features <- test_data[, 1:10]
test_labels <- as.factor(test_data[, 11])
# Feature Scaling
train_scale <- scale(train_features)
test_scale <- scale(test_features)
#------------------------- loop through different values of K
# Define a vector to store accuracy for each K
accuracies <- c()
# Loop through values of K from 1 to 10
for (K_value in 1:10) {
# Fitting knn model to training dataset
pred <- knn(train = train_scale,
test = test_scale,
cl = train_labels,
k = K_value)
# Calculate accuracy by comparing predictions to actual class labels
accuracy <- sum(pred == test_labels) / length(test_labels)
# Print the K value and corresponding accuracy
print(paste("K =", K_value, "-> Accuracy:", accuracy))
# Store the accuracy for each model
accuracies <- c(accuracies, accuracy)
}
#------------------------- output final accuracies for each model
print("Accuracies for each KNN model with varying K:")
print(accuracies)
#------------------------- getting a sense of the data
# Reading in the credit card data
credit <- read.table("C://Users//Clair//OneDrive//Documents//Fall 2024//IYSE 6501//hw1//data 2.2//credit_card_data.txt", sep="\t", header=FALSE)
#------------------------- manipulating the data
# Converting to matrix
credit_matrix <- data.matrix(credit)
#------------------------- helper libraries
library(class)
library(caTools)
library(ggplot2)
#------------------------- split data into train and test sets
set.seed(123)  # For reproducibility
split <- sample.split(credit_matrix[, 11], SplitRatio = 0.7)
# Subset the credit_matrix into training and testing data
train_data <- subset(credit_matrix, split == TRUE)
test_data <- subset(credit_matrix, split == FALSE)
# Separating the features and labels for train and test data
train_features <- train_data[, 1:10]
train_labels <- as.factor(train_data[, 11])
test_features <- test_data[, 1:10]
test_labels <- as.factor(test_data[, 11])
# Feature Scaling
train_scale <- scale(train_features)
test_scale <- scale(test_features)
#------------------------- loop through different values of K
# Define a vector to store accuracy for each K
accuracies <- c()
# Loop through values of K from 1 to 10
for (K_value in 1:10) {
# Fitting KNN model to training dataset
pred <- knn(train = train_scale,
test = test_scale,
cl = train_labels,
k = K_value)
# Calculate accuracy by comparing predictions to actual class labels
accuracy <- sum(pred == test_labels) / length(test_labels)
# Print the K value and corresponding accuracy
print(paste("K =", K_value, "-> Accuracy:", accuracy))
# Store the accuracy for each model
accuracies <- c(accuracies, accuracy)
}
#------------------------- output final accuracies for each model
print("Accuracies for each KNN model with varying K:")
print(accuracies)
#------------------------- plotting the results using ggplot2
# Create a dataframe with K values and corresponding accuracies
accuracy_data <- data.frame(
K = 1:10,
Accuracy = accuracies
)
# Explicitly printing the plot
plot <- ggplot(accuracy_data, aes(x = K, y = Accuracy)) +
geom_line(color = "blue", size = 1) +    # Line graph
geom_point(color = "red", size = 3) +    # Points on the graph
labs(title = "KNN Accuracy for Different K Values",
x = "K Value",
y = "Accuracy") +
scale_y_continuous(labels = scales::percent) +   # Show accuracy as percentage
theme_minimal()
print(plot)  # Explicitly render the plot

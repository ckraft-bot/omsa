---
title: "Homework_8"
author: "Claire Kraft"
date: "2024-10-15"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Question 11.1
**Using the crime data set uscrime.txt from Questions 8.2, 9.1, and 10.1, build a regression model using:**
  1. Stepwise regression
  2. Lasso
  3. Elastic net
**For Parts 2 and 3, remember to scale the data first – otherwise, the regression coefficients will be on different scales and the constraint won’t have the desired effect.**

In Stepwise regression i first create a regression that takes in all factors to find highly correlative factors. I think in a previous homework we did a similar exercise to extract the best factors. I don't recall what those factors were but based on the results from this code snippet, the best factors are (Ed, M.f) which have p-values of 0.1 or better. After running the forward and backward the R Squared result came out to be 0.1446551 meaning there is a 14.47% variance. I'm going to pull in a few more factors (Ed + M.F + Po1 + Po2 + Ineq) to see how the performance compares. The R Squared result did jump up to 0.7304136 or 73.04% variance. This lm_broad model seems more robust.

```{r shelper}
# Helper 
#install.packages("glmnet")
library(ggplot2)
library(glmnet)
library(tree)
```


```{r stepwise reg}
# Set up
rm(list = ls())

# Read in data
uscrime <- read.table("~/GitHub/omsa/ISYE 6501/Homework 08/uscrime.txt", stringsAsFactors = FALSE, header = TRUE)
head(uscrime)

# Set seed for reproducibility
set.seed(123)
# 70% of the data
train_size <- floor(0.70 * nrow(uscrime))

# Randomly sample indices for the training set
train_indices <- sample(seq_len(nrow(uscrime)), size = train_size)

# Split the data into training and test sets - 70/30
train_data <- uscrime[train_indices, ]
test_data <- uscrime[-train_indices, ]

# Display the dimensions of the training and test sets
dim(train_data) # Should be approximately 33 x 16
dim(test_data)  # Should be approximately 14 x 16

#-------------------------- Stepwise reg - lm_slim
# Fit model
lm_everything <- lm(train_data$Crime ~., train_data[1:15])
# Find high correlations by taking in all factors
lm_everything_summary <- summary(lm_everything)
# Look for twinkle twinkle stars
print(lm_everything_summary)

# Forward and backward
# Look at reference 1
lm_slim <- lm(Crime ~ Ed + M.F, data = train_data)
# Should be highly correlative
lm_slim_summary <- summary(lm_slim)
# Look for twinkle twinkle stars
print(lm_slim_summary)


forward <- step(lm_slim, direction = 'forward', scope = formula(~ .))
forward
backward <- step(lm_slim, direction = 'backward', trace = 0)
backward

# Predict on the training data
predictions_slim <- predict(lm_slim, newdata = train_data)

# Calculate the total sum of squares (SST)
# Look at reference 2
sst_slim <- sum((train_data$Crime - mean(train_data$Crime))^2)

# Calculate the sum of squared errors (SSE)
# Look at reference 2
sse_slim <- sum((train_data$Crime - predictions_slim)^2)

# Calculate R-squared
# Look at reference 2
r2_slim <- 1 - (sse_slim / sst_slim)
r2_slim


#-------------------------- Stepwise reg - lm_broad
# Forward and backward
# Look at reference 1
lm_broad <- lm(Crime ~ Ed + M.F + Po1 + Po2 + Ineq, data = train_data)
# Should be highly correlative
lm_broad_summary <- summary(lm_broad)
# Look for twinkle twinkle stars
print(lm_broad_summary)


forward <- step(lm_broad, direction = 'forward', scope = formula(~ .))
forward
backward <- step(lm_broad, direction = 'backward', trace = 0)
backward


# Predict on the training data
predictions_broad <- predict(lm_broad, newdata = train_data)

# Calculate the total sum of squares (SST)
# Look at reference 2
sst_broad <- sum((train_data$Crime - mean(train_data$Crime))^2)

# Calculate the sum of squared errors (SSE)
# Look at reference 2
sse_broad <- sum((train_data$Crime - predictions_broad)^2)

# Calculate R-squared
# Look at reference 2
r2_broad <- 1 - (sse_broad / sst_broad)
r2_broad
```



```{r lasso}
# Set up
rm(list = ls())

# Read in data
uscrime <- read.table("~/GitHub/omsa/ISYE 6501/Homework 08/uscrime.txt", stringsAsFactors = FALSE, header = TRUE)
head(uscrime)
# Scale data
uscrime_scaled <- data.frame(scale(uscrime[1:15]), Crime = uscrime$Crime)
head(uscrime_scaled)


# Set seed for reproducibility
set.seed(123)
# 70% of the data
train_size <- floor(0.70 * nrow(uscrime_scaled))

# Randomly sample indices for the training set
train_indices <- sample(seq_len(nrow(uscrime_scaled)), size = train_size)

# Split the data into training and test sets - 70/30
train_data <- uscrime_scaled[train_indices, ]
test_data <- uscrime_scaled[-train_indices, ]

# Display the dimensions of the training and test sets
dim(train_data) # Should be approximately 33 x 16
dim(test_data)  # Should be approximately 14 x 16

```

```{r elasntic net}
# Set up
rm(list = ls())

# Read in data
uscrime <- read.table("~/GitHub/omsa/ISYE 6501/Homework 08/uscrime.txt", stringsAsFactors = FALSE, header = TRUE)
head(uscrime)
```

### Question 11.2 Part 2
**For Parts 2 and 3, remember to scale the data first – otherwise, the regression coefficients will be on different scales and the constraint won’t have the desired effect. For Parts 2 and 3, use the glmnet function in R.**

answer
```{r part 2}
#code
```

### Question 11.2 Part 3
****For Parts 2 and 3, remember to scale the data first – otherwise, the regression coefficients will be on different scales and the constraint won’t have the desired effect. For Parts 2 and 3, use the glmnet function in R.****

answer
```{r part 3}
#code
```



References:

[1] Sanderson, S. P. (2023, December 6). Steve’s Data Tips and Tricks - A Complete Guide to Stepwise Regression in R. Steve’s Data Tips and Tricks. https://www.spsanderson.com/steveondata/posts/2023-12-06/index.html

[2] Function to calculate R2 (R-squared) in R. (n.d.). Stack Overflow. https://stackoverflow.com/questions/40901445/function-to-calculate-r2-r-squared-in-r

[3] APA citation

[4] APA citation

[5] APA citation

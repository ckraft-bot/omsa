---
title: "Homework_3"
author: "Claire Kraft"
date: "2024-09-08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Question 5.1
**Using crime data from the file uscrime.txt (http://www.statsci.org/data/general/uscrime.txt, description at http://www.statsci.org/data/general/uscrime.html), test to see whether there are any outliers in the last column (number of crimes per 100,000 people).  Use the grubbs.test function in the outliers package in R.**

I first ran the grubb test function and chose the second test with this argument ```type=11``` which checks for the opposite extreme ends of the data. It compares the range (difference between the smallest and largest values) to the standard deviation of the data [1]. The p-value is a metric for how valid our observation is. The lower the p value the more statistically significant the observation, the higher the less statistically significant. The p-value is 1 for this grub test. It's best to take this observation with a grain of salt as this is statistically _insignificant_ [3]. 

I then ran the whiskers box plot and there are three outliers [2].

```{r grubb test & whisker plot}
#------------------------- Libraries
#install.packages("outliers")
#install.packages("tidyverse")
library(outliers)
library(ggplot2)

#------------------------- Load and explore data
crime_df <- read.table("C://Users//Clair//OneDrive//Documents//GitHub//omsa//ISYE 6501//Homework 3//uscrime.txt", sep = "\t", header = TRUE)
head(crime_df)
summary(crime_df)

#------------------------- Detect outliers on simulated data
# Perform grubbs test
# look at reference 1
grubbs.test(crime_df$Crime,type=11, opposite = FALSE, two.sided = FALSE) 

#------------------------- Visualize original crime data
# look at reference 2
# Check the column names in your dataset
colnames(crime_df)
# Sample data
data(crime_df)
# Simple boxplot 
ggplot(crime_df, aes(x = "", y = Crime)) + 
    geom_boxplot() + 
    labs(title = "Number of Crimes Per 100,000 People")
```



## Question 6.1
**Describe a situation or problem from your job, everyday life, current events, etc., for which a Change Detection model would be appropriate. Applying the CUSUM technique, how would you choose the critical value and the threshold?**

CUSUM is used to detect the changes (increases or decreases) in data. The slower the changes detected the less likely to falsely detect changes. I already track changes on all my bills. It would be neat to apply the CUSUM approach with my non fixed bills. For example my water, sewer, and electricity bills vary by consumption. I have the historical data gathered, With about 2 years of data collection, I have ran an exploratory data analysis (EDA). In the EDA I have the basic statistics (mean, median, standard deviation, percentiles, etc) with the ```describe()``` python function. The mean and standard deviations are sufficient enough to see my trends and baseline overtime. For the critical value (k) maybe I'll set that at 10% change from the standard deviation price. As for the threshold (h) I'll set it at double of critical value because every penny counts and i want to be alerted as that threshold even if it may seem conservative.

_my pretend values_\
critical value = 0.10

std dev = $100

k=(0.10*$100) = $10

threshold = 2

h = (2*$10) = $20


_variables_\
ct = CUSUM for current month

ct-1 = CUSUM for previous month

xt = current bill

k: critical value

h: threshold


_formula_\
Ct = max(0,Ct−1+(xt−mean−k))


### Question 6.2.1
**Using July through October daily-high-temperature data for Atlanta for 1996 through 2015, use a CUSUM approach to identify when unofficial summer ends (i.e., when the weather starts cooling off) each year. You can get the data that you need from the file temps.txt or online, for example at http://www.iweathernet.com/atlanta-weather-records or https://www.wunderground.com/history/airport/KFTY/2015/7/1/CustomHistory.html. You can use R if you’d like, but it’s straightforward enough that an Excel spreadsheet can easily do the job too.**

I used Excel for this analysis. The data covers July through October from 1996 to 2015. I first aggregated every temperature in the dataset and found an average of 83.34 degrees. Then, I aggregated all the temperatures by month across all years to identify the hottest month. The average temperature, across all the years, is 88.75 degrees in July, 88.62 degrees in September, and 82.67 degrees in October. Using these three averages, I defined July as the peak of “summer” since it has the highest average temperature.

I set 88.75 as my baseline mean (μ). For critical values, I wanted to use 2.5 standard deviations away. According to the normal bell curve principle, most data falls within ±2 standard deviations, covering about 95% of the data[5]. Therefore, I used the formula ```k=2*std dev``` for my critical value. For the thresholds, I calculated an upper threshold (UH) and a lower threshold (LH). The upper threshold formula is ```uh=mean+k``` and the lower threshold formula is ```lh=mean-k```.

Since the goal is to determine when summer ends, I prioritized the lower threshold to calculate the CUSUM. In other words, temperatures below 83.75 degrees indicate the end of summer. I then used conditional highlighting (highlighting any data below the lower threshold value) to see when the temperatures began to drop, signaling a season change. As a gut check, it seems that mid-September is when summer ends, as most days meet the lower threshold. If we had to pick a specific date on the season change then September 22nd would be date as there are no temperatures above the upper threshold. 

_formulas_\
Ct = max(0,Ct−1+(xt−mean−k))

_formulas detailed_\
mean = 88.75

std dev = 2.5 

k = 5

uh = 93.75

lh = 83.75


```{r atlanta summer}
#------------------------- Libraries
#install.packages("outliers")
#install.packages("tidyverse")
library(outliers)
library(ggplot2)

# Load and explore data
temps_df <- read.table("C://Users//Clair//OneDrive//Documents//GitHub//omsa//ISYE 6501//Homework 3//temps.txt", sep = "\t", header = TRUE)
summary(temps_df)
View(head(temps_df))

# Remove the 'x' from all column headers
# look at reference 4
colnames(temps_df) <- gsub("X", "", colnames(temps_df))

# View the first few rows of the updated dataframe
View(head(temps_df))
```


### Question 6.2.2
**Use a CUSUM approach to make a judgment of whether Atlanta’s summer climate has gotten warmer in that time (and if so, when).**

In my observation mid September is the beginning to the end of summer. September 22nd is the first day of fall. Looking at September 22nd year of year it looks like the temps are steadily getting higher. In the late 90s the temps sit at 70 degrees. Then 2004-2014 with the exception of 2010 sit at 80 some degrees. 2010 is unusually high at 92 degrees. 2015 drops back down to 76 degrees to match the trends of the late 90s. In summer the same date (September 22nd) year over year is getting hotter.


References:

[1] Grubbs, F.E. (1950). Sample Criteria for testing outlying observations. Ann. Math. Stat. 21, 1, 27-58.

[2] Holtz, Y. (n.d.). Basic ggplot2 boxplot. Www.r-Graph-Gallery.com. https://r-graph-gallery.com/262-basic-boxplot-with-ggplot2.html

[3] Simplilearn. (2022, August 30). What Is P-Value in Statistical Hypothesis? | Simplilearn. Simplilearn.com. https://www.simplilearn.com/tutorials/statistics-tutorial/p-value-in-statistics-hypothesis

[4] r Remove parts of column name after certain characters. (n.d.). Stack Overflow. https://stackoverflow.com/questions/37800704/r-remove-parts-of-column-name-after-certain-characters

[5] Frost, J. (2021, August 31). Empirical Rule: Definition, Formula, and Uses. Statistics by Jim. https://statisticsbyjim.com/probability/empirical-rule/
